"0","spotify_daily <- spotify |>"
"0","  group_by(date) |>"
"0","  summarize(mins_daily = sum(ms_played)/60000, "
"0","            danceability_daily = mean(danceability), "
"0","            energy_daily = mean(energy),"
"0","            loudness_daily = mean(loudness_norm), "
"0","            acousticness_daily = mean(acousticness),"
"0","            instrumentalness_daily = mean(instrumentalness),"
"0","            liveness_daily = mean(liveness),"
"0","            valence_daily = mean(valence), "
"0","            tempo_daily = mean(tempo_norm))"
"0",""
"0","daily_data <- full_join(spotify_daily, steps, join_by = ""date"") #introduce NA here, days where i have steps but no music data "
"1","[38;5;252mJoining, by = ""date""[39m
"
"0","daily_data <- filter(daily_data, date >= ""2016-05-26"" & date <= ""2022-03-14"") #Chose to filter from this date since I have extremely limited music data before this date"
"0",""
"0","apply(daily_data, 2, VIM::countNA)"
"1","                  date "
"1","            mins_daily "
"1","    danceability_daily "
"1","          energy_daily "
"1","
"
"1","                     0 "
"1","                    60 "
"1","                    60 "
"1","                    60 "
"1","
"
"1","        loudness_daily "
"1","    acousticness_daily "
"1","instrumentalness_daily "
"1","        liveness_daily "
"1","
"
"1","                    60 "
"1","                    60 "
"1","                    60 "
"1","                    60 "
"1","
"
"1","         valence_daily "
"1","           tempo_daily "
"1","           steps_daily "
"1","
"
"1","                    60 "
"1","                    60 "
"1","                    26 "
"1","
"
"0","which(is.na(daily_data$mins_daily), arr.ind = TRUE)"
"1"," [1]"
"1"," 2059"
"1"," 2060"
"1"," 2061"
"1"," 2062"
"1"," 2063"
"1"," 2064"
"1"," 2065"
"1"," 2066"
"1"," 2067"
"1"," 2068"
"1"," 2069"
"1"," 2070"
"1"," 2071"
"1"," 2072"
"1"," 2073"
"1"," 2074"
"1"," 2075"
"1"," 2076"
"1"," 2077"
"1"," 2078"
"1","
"
"1","[21]"
"1"," 2079"
"1"," 2080"
"1"," 2081"
"1"," 2082"
"1"," 2083"
"1"," 2084"
"1"," 2085"
"1"," 2086"
"1"," 2087"
"1"," 2088"
"1"," 2089"
"1"," 2090"
"1"," 2091"
"1"," 2092"
"1"," 2093"
"1"," 2094"
"1"," 2095"
"1"," 2096"
"1"," 2097"
"1"," 2098"
"1","
"
"1","[41]"
"1"," 2099"
"1"," 2100"
"1"," 2101"
"1"," 2102"
"1"," 2103"
"1"," 2104"
"1"," 2105"
"1"," 2106"
"1"," 2107"
"1"," 2108"
"1"," 2109"
"1"," 2110"
"1"," 2111"
"1"," 2112"
"1"," 2113"
"1"," 2114"
"1"," 2115"
"1"," 2116"
"1"," 2117"
"1"," 2118"
"1","
"
"0","#All NA are at the bottom of the dataset but the dates they span are random ie. MAR."
"0",""
"0","#I did not remove NA's from this data set. They're probably interesting..."
